#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import re
import atexit
import requests
from copy import deepcopy
from logger import logger
import streamlit as st
from typing import List
from functions import tools, run_python
from VectorDatabase import VectorDatabase
from embedding import EmbeddingAPI, RerankEmbeddingAPI, BM25
from document import TextDocument, PDFDocument, SheetDocument
from Retriever import HyDE, Route, Retriever, SheetRetriever, ChartRetriever
from template import API_LIST, RAG_TEMPLATE_NEW, RAG_TEMPLATE_IE, RAG_TEMPLATE_CHART, DOCUMENT_SELECTED


DOCUMENT_TMP_PATH = "./tmp/"

st.title("æ–‡æ¡£é—®ç­”æŠ•ç ” Agent ç³»ç»Ÿ")


def clear_tmp_files(file_list: list):
    for file in file_list:
        if os.path.exists(file): os.remove(file)
        if os.path.exists(".".join(file.split('.')[: -1]) + ".txt"): os.remove(".".join(file.split('.')[: -1]) + ".txt")

# æ·»åŠ ä¸€ä¸ªé‡ç½®æŒ‰é’®
if st.sidebar.button('é‡ç½®ç³»ç»Ÿ'):
    clear_tmp_files(st.session_state.file_list)
    st.session_state.clear()

if st.sidebar.button('æ¸…ç©ºå¯¹è¯'):
    st.session_state.messages = []

# ä¸´æ—¶å­˜æ”¾æ–‡ä»¶
if not os.path.exists(DOCUMENT_TMP_PATH):
    os.makedirs(DOCUMENT_TMP_PATH)

if "file_list" not in st.session_state:
    st.session_state.file_list = []


atexit.register(clear_tmp_files, st.session_state.file_list)


def build_knowledge_chat_bot():
    """åˆ›å»ºçŸ¥è¯†é—®ç­”æœºå™¨äºº"""
    def knowledge_chat_bot(query, sents): 
        prompt = RAG_TEMPLATE_NEW.format(
                            context="\n".join([f"[{i+1}] {s.strip()}" for i, s in enumerate(sents)]), 
                            query=query)
        logger.info(f"chat model prompt: {prompt}")
        return requests.post(API_LIST["qwen1half-14b-chat"]["url"], 
            json={"messages": [{"role": "user", "content": prompt}], 
                  "model": "qwen1half-14b-chat", 
                  "stream": False, 
                #   "tools": tools,
                #   "tool_choice": None
                  },
            headers=API_LIST["qwen1half-14b-chat"]["headers"]).json()["choices"][0]["message"]["content"]
    return knowledge_chat_bot


def build_knowledge_ie_bot():
    """åˆ›å»ºä¿¡æ¯æŠ½å–æœºå™¨äºº"""
    def knowledge_ie_bot(query, sents): 
        prompt = RAG_TEMPLATE_IE.format(
                            context="\n".join([f"[{i+1}] {s.strip()}" for i, s in enumerate(sents)]), 
                            query=query)
        logger.info(f"ie model prompt: {prompt}")
        return requests.post(API_LIST["qwen1half-14b-chat"]["url"], 
            json={"messages": [{"role": "user", "content": prompt}], 
                  "model": "qwen1half-14b-chat", 
                  "stream": False},
            headers=API_LIST["qwen1half-14b-chat"]["headers"]).json()["choices"][0]["message"]["content"]
    return knowledge_ie_bot


def build_knowledge_chart_bot():
    """åˆ›å»ºå›¾è¡¨é—®ç­”æœºå™¨äºº"""
    def knowledge_chart_bot(query, sents): 
        prompt = RAG_TEMPLATE_CHART.format(
                            context="\n".join([f"[{i+1}] {s.strip()}" for i, s in enumerate(sents)]), 
                            query=query)
        logger.info(f"chart model prompt: {prompt}")
        return requests.post(API_LIST["qwen1half-14b-chat"]["url"], 
            json={"messages": [{"role": "user", "content": prompt}], 
                  "model": "qwen1half-14b-chat", 
                  "stream": False},
            headers=API_LIST["qwen1half-14b-chat"]["headers"]).json()["choices"][0]["message"]["content"]
    return knowledge_chart_bot


def build_document_selected_bot():
    """åˆ›å»ºæ–‡æ¡£é€‰æ‹©æœºå™¨äºº"""
    def document_selected_bot(query): 
        prompt = DOCUMENT_SELECTED.format(query=query)
        logger.info(f"document selected model prompt: {prompt}")
        return requests.post(API_LIST["qwen1half-14b-chat"]["url"], 
            json={"messages": [{"role": "user", "content": prompt}], 
                  "model": "qwen1half-14b-chat", 
                  "stream": False},
            headers=API_LIST["qwen1half-14b-chat"]["headers"]).json()["choices"][0]["message"]["content"]
    return document_selected_bot


def markdown_to_plaintext(markdown_text):
    # ç§»é™¤æ ‡é¢˜
    plaintext = re.sub(r'#+', '', markdown_text)
    # ç§»é™¤åŠ ç²—å’Œæ–œä½“
    plaintext = re.sub(r'[*_]{1,3}', '', plaintext)
    # ç§»é™¤é“¾æ¥
    plaintext = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', plaintext)
    # ç§»é™¤å¼•ç”¨
    plaintext = re.sub(r'>+', '', plaintext)
    # ç§»é™¤æ— åºåˆ—è¡¨
    plaintext = re.sub(r'- \[ \] ', '', plaintext)
    plaintext = re.sub(r'- [x] ', '', plaintext)
    plaintext = re.sub(r'- ', '', plaintext)
    # ç§»é™¤æœ‰åºåˆ—è¡¨
    plaintext = re.sub(r'\d+\.', '', plaintext)
    # ç§»é™¤åˆ†éš”çº¿
    plaintext = re.sub(r'---+', '', plaintext)
    # ç§»é™¤HTMLæ ‡ç­¾
    plaintext = re.sub(r'<[^>]+>', '', plaintext)
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    plaintext = re.sub(r'(?!<=\d)(?<!\.)\s+', ' ', plaintext).strip()
    return plaintext


def add_cite(response: str, segment_list: List[str]) -> str:
    """
    ä¸ºå›å¤æ·»åŠ æ–‡æ®µå‚è€ƒå¼•ç”¨ï¼Œç”¨äºè§‚å¯Ÿå¬å›æ•ˆæœ

    Args:
        response (str): æ¨¡å‹çš„å›å¤
        segment_list (list[str]): å¬å›çš„æ–‡æ®µåˆ—è¡¨

    Returns:
        None: å¤„ç†åçš„ md æ ¼å¼å›å¤
    """
    response = re.sub(r'(\d),(\d)', r'\1\2', response)
    # response = re.sub(r'\^ã€([0-9]+)â€ æ¥æºã€‘\^', r'[\^{\1}\]', response)   # å•å¼•ç”¨æ ¼å¼
    for i in range(len(segment_list)):
        response = response.replace(f"ã€{i+1}â€ æ¥æºã€‘", f"[^{i+1}]")

    # response = re.sub(r'ã€([0-9]+)â€ æ¥æºã€‘ã€([0-9]+)â€ æ¥æºã€‘', r'[\^{\1}][\^{\2}\]', response)   # å¤šå¼•ç”¨æ ¼å¼
    response = response.replace("ã€1â€ 2â€ æ¥æºã€‘", "[^1][^2]")
    response = response.replace("ã€1â€ 3â€ æ¥æºã€‘", "[^1][^3]")
    response = response.replace("ã€2â€ 3â€ æ¥æºã€‘", "[^2][^3]")
    # æ–‡æœ«æ·»åŠ æœªè¢«æ¨¡å‹å¼•ç”¨çš„éšè—å¼•ç”¨æ ¼å¼ï¼Œç¡®ä¿èƒ½æŠŠæœªå¼•ç”¨çš„æ–‡æ®µä¹Ÿæ˜¾ç¤ºå‡ºæ¥
    response += f'<span style="visibility:hidden">\
                {"".join([f"[^{i+1}]" for i in range(len(segment_list))])}.</span>'

    cites = []
    # æ ¼å¼åŒ–å¬å›çš„æ–‡æ®µ
    for i, s in enumerate(segment_list):
        name = s.split("æ–‡æ¡£é‡Œï¼Œç›®å½•å±‚çº§ä¸ºï¼š", 1)[0]   # æå–æ–‡æ¡£å
        if name == s:   # è‹¥æ–‡æ¡£åä¸ç¬¦åˆé€šç”¨æ ¼å¼
            name = s.split("æ–‡æ¡£ä»¥ä¸‹ä¸ºæ­£æ–‡å†…å®¹", 1)[0]
            title = ""   # è¿™ç§æ ¼å¼æ— æ ‡é¢˜
        else:   # ç¬¦åˆé€šç”¨æ ¼å¼ï¼Œæå–æ ‡é¢˜å¹¶æ–œä½“è¡¨ç¤º
            title = "*" + s.split("ï¼Œä»¥ä¸‹ä¸ºæ­£æ–‡å†…å®¹ï¼š", 1)[0].split("ç›®å½•å±‚çº§ä¸ºï¼š")[-1] + "*"
        content = s.split("ä»¥ä¸‹ä¸ºæ­£æ–‡å†…å®¹ï¼š", 1)[-1].strip("*").strip("#").strip("`").strip("- ").replace("\n", " ").replace('\r', '')   # æå–æ–‡æ®µ
        content = markdown_to_plaintext(content)
        item = f"[^{i+1}]: ã€Š{name}ã€‹ï¼š{title}  \n{content}"
        cites.append(item)
    
    response += "  \n" + "  \n".join(cites)
    return response


def display_dialog() -> None:
    """
    æ¸²æŸ“å¯¹è¯

    Args:
        segment_list (list[str]):  æ–‡æ®µåˆ—è¡¨

    Returns:
        None: æ— è¿”å›å€¼
    """
    # æ¸²æŸ“å¯¹è¯å†…å®¹
    for message in st.session_state.messages:  # æ¸²æŸ“å†å²è®°å½•
        if message["role"] == "assistant":
            with st.chat_message("assistant"):
                st.markdown(message["content"], unsafe_allow_html=True)
        else:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])


if "embedding" not in st.session_state:
    st.session_state.embedding = EmbeddingAPI()

if "db_short" not in st.session_state:
    st.session_state.db_short = []

if "db_long" not in st.session_state:
    st.session_state.db_long = []

if "rerank" not in st.session_state:
    st.session_state.rerank = RerankEmbeddingAPI()

if "hyde" not in st.session_state:
    st.session_state.hyde = {}
    st.session_state.hyde["concise"] = HyDE(api_name="concise")
    st.session_state.hyde["glm"] = HyDE(api_name="glm")
    st.session_state.hyde["step"] = HyDE(api_name="step")
    st.session_state.hyde["qwen"] = HyDE(api_name="qwen")
    

if "messages" not in st.session_state:
    st.session_state.messages = []
    

if "document" not in st.session_state:
    st.session_state.document = {}
    st.session_state.document["txt"] = {}
    st.session_state.document["txt"].update({"long": []})
    st.session_state.document["txt"].update({"short": []})
    st.session_state.document["pdf"] = {}
    st.session_state.document["pdf"].update({"long": []})
    st.session_state.document["pdf"].update({"short": []})
    st.session_state.document["sheet"] = []
    
if "knowledge_chat_bot" not in st.session_state:
    knowledge_chat_bot = build_knowledge_chat_bot()
    st.session_state.knowledge_chat_bot = knowledge_chat_bot

if "knowledge_ie_bot" not in st.session_state:
    knowledge_ie_bot = build_knowledge_ie_bot()
    st.session_state.knowledge_ie_bot = knowledge_ie_bot

if "knowledge_chart_bot" not in st.session_state:
    knowledge_chart_bot = build_knowledge_chart_bot()
    st.session_state.knowledge_chart_bot = knowledge_chart_bot

if "document_selected_bot" not in st.session_state:
    document_selected_bot = build_document_selected_bot()
    st.session_state.document_selected_bot = document_selected_bot

if "sheet_chat_bot" not in st.session_state:
    st.session_state.sheet_chat_bot = SheetRetriever()


# æ–‡ä»¶ä¸Šä¼ 
st.sidebar.write("\n")
st.sidebar.write("\n")
postfix_type = {"txt": "txt", "md": "txt", "csv": "sheet", "pdf": "pdf", "xlsx": "sheet"}
header = st.sidebar.selectbox('**è‹¥ä¸Šä¼ è¡¨æ ¼ï¼Œè¯·å…ˆé€‰æ‹©è¡¨æ ¼é¦–è¡Œï¼ˆæœ‰åˆ—åçš„è¡Œï¼‰ç´¢å¼•ï¼Œå†ä¸Šä¼ æ–‡ä»¶**', [None, 0, 1, 2, 3, 4, 5])
uploaded_files: list = st.sidebar.file_uploader("è¯·ä¸Šä¼ æ–‡ä»¶ï¼ˆtxt, csv, PDF, Markdown, Excelï¼‰", 
                                               type=list(postfix_type.keys()), accept_multiple_files=True)


# è‹¥ä¸Šä¼ çš„æ–‡ä»¶å­˜åœ¨
if uploaded_files is not None:
    file_names = [".".join(uploaded_file.name.split(".")[: -1]) + "." + uploaded_file.name.split(".")[-1].lower()
                 for uploaded_file in uploaded_files]

    # æ‹Ÿä¿å­˜çš„æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    file_paths = [os.path.join(DOCUMENT_TMP_PATH, file_name) for file_name in file_names]
    st.session_state.file_list += file_paths
    file_types = [postfix_type.get(file_name.split(".")[-1]) for file_name in file_names]

    # åˆå§‹åŒ–è¿›åº¦æ¡
    if file_names:
        my_bar = st.progress(0)
    placeholder = st.empty()
    if file_types and len(st.session_state.document[file_types[0]]["long"]) < len(uploaded_files):
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¿å­˜ï¼Œå¦åˆ™ç›´æ¥æç¤ºä¸Šä¼ æˆåŠŸ
        with st.spinner('æ­£åœ¨ä¿å­˜æ–‡æ¡£ ...'):
            for i, file_path, uploaded_file in zip(range(len(file_paths)), file_paths, uploaded_files):
                if not os.path.exists(file_path):
                    # ä¿å­˜æ–‡ä»¶
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
        placeholder.success(f'æ–‡æ¡£ä¿å­˜å®Œæˆï¼', icon="âœ…")
        my_bar.progress(0.20, "ä¿å­˜æ–‡æ¡£âœ…  -â†’  **æ–‡æœ¬åˆ†æ®µ**â³  -â†’  æ®µè½ EmbeddingsğŸ•›  -â†’  å­˜å…¥ FaissğŸ•›  -â†’  è®¡ç®— BM25ğŸ•›")
        
        # åˆ†å¥
        with st.spinner('æ­£åœ¨åˆ†æ®µ ...'):
            for i, file_path, file_type in zip(range(len(file_paths)), file_paths, file_types):
                if file_type == "sheet":
                    st.session_state.document[file_type].append(SheetDocument.read_sheet(file_path, header))

                else:
                    # æ–°æ–‡æ¡£éœ€è¦å¯¼å…¥ document åˆ‡åˆ†
                    obj_long = PDFDocument() if file_type == "pdf" else TextDocument()
                    sentences_long = obj_long.input_documents(file_path, max_length=768)
                    st.session_state.document[file_type]["long"].append(deepcopy(obj_long))
                    
                    obj_short = PDFDocument() if file_type == "pdf" else TextDocument()
                    sentences_short = obj_short.input_documents(file_path, max_length=384)
                    st.session_state.document[file_type]["short"].append(deepcopy(obj_short))
                    
                    if "sentences_long" not in st.session_state:
                        st.session_state.sentences_long = [sentences_long]
                    else:
                        st.session_state.sentences_long.append(sentences_long)
                    if "sentences_short" not in st.session_state:
                        st.session_state.sentences_short = [sentences_short]
                    else:
                        st.session_state.sentences_short.append(sentences_short)

        placeholder.success('æ–‡ä»¶åˆ†æ®µå®Œæˆï¼', icon="âœ…")
        my_bar.progress(0.40, "ä¿å­˜æ–‡æ¡£âœ…  --â†’  æ–‡æœ¬åˆ†æ®µâœ…  --â†’  **æ®µè½ Embeddings**â³  --â†’  å­˜å…¥ FaissğŸ•›  --â†’  è®¡ç®— BM25ğŸ•›") 
            
        # åµŒå…¥
        with st.spinner('æ­£åœ¨ Embedding ...'):
            start_len_longs, start_len_shorts = [], []   # [{'id': i, 'len': len(d)}, ...]
            sentences_long, sentences_short = [], []
            i, j = 0, 0
            for d in st.session_state.sentences_long:
                start_len_longs.append({'id': i, 'len': len(d)})
                sentences_long += d
                i += len(d)
            for d in st.session_state.sentences_short:
                start_len_shorts.append({'id': j, 'len': len(d)})
                sentences_short += d
                j += len(d)
                
            long_len = len(sentences_long)
            embeddings = st.session_state.embedding(sentences_long + sentences_short, is_query=False)
            embeddings_long, embeddings_short = embeddings[: long_len], embeddings[long_len: ]
            
            embeddings_longs, embeddings_shorts = [], []
            for d in start_len_longs:
                embeddings_longs.append(embeddings_long[d['id']: d['id'] + d['len']])
            for d in start_len_shorts:
                embeddings_shorts.append(embeddings_short[d['id']: d['id'] + d['len']])

        placeholder.success('Embedding å®Œæˆï¼', icon="âœ…")
        my_bar.progress(0.60, "ä¿å­˜æ–‡æ¡£âœ…  --â†’  æ–‡æœ¬åˆ†æ®µâœ…  --â†’  æ®µè½ Embeddingsâœ…  --â†’  **å­˜å…¥ Faiss**â³  --â†’  è®¡ç®— BM25ğŸ•›")
        
        # å­˜å…¥ Faiss
        with st.spinner('æ­£åœ¨å­˜å…¥ Faiss ...'):
            for i, embeddings_long, embeddings_short in zip(range(len(embeddings_longs)), embeddings_longs, embeddings_shorts):
                obj_long = VectorDatabase(n_hiddens=1024, db_name=f"long_{file_names[i]}")
                obj_long.create_index(embeddings_long)
                st.session_state.db_long.append(obj_long)
                
                obj_short = VectorDatabase(n_hiddens=1024, db_name=f"short_{file_names[i]}")
                obj_short.create_index(embeddings_short)
                st.session_state.db_short.append(obj_short)
        placeholder.success('å­˜å…¥ Faiss å®Œæˆï¼', icon="âœ…")
        my_bar.progress(0.80, "ä¿å­˜æ–‡æ¡£âœ…  --â†’  æ–‡æœ¬åˆ†æ®µâœ…  --â†’  æ®µè½ Embeddingsâœ…  --â†’  å­˜å…¥ Faissâœ…  --â†’  **è®¡ç®— BM25**â³")  
        
        # è®¡ç®— BM25
        with st.spinner('æ­£åœ¨è®¡ç®— BM25 ...'):
            for sentences_long, sentences_short in zip(st.session_state.sentences_long, st.session_state.sentences_short):
                if "bm25_long" not in st.session_state:
                    st.session_state.bm25_long = [BM25(sentences_long)]
                else:
                    st.session_state.bm25_long.append(BM25(sentences_long))
                if "bm25_short" not in st.session_state:
                    st.session_state.bm25_short = [BM25(sentences_short)]
                else:
                    st.session_state.bm25_short.append(BM25(sentences_short))
        placeholder.success('BM25 è®¡ç®—å®Œæˆï¼', icon="âœ…")
        my_bar.progress(1.00, "ä¿å­˜æ–‡æ¡£âœ…  --â†’  æ–‡æœ¬åˆ†æ®µâœ…  --â†’  æ®µè½ Embeddingsâœ…  --â†’  å­˜å…¥ Faissâœ…  --â†’  è®¡ç®— BM25âœ…")
            
        placeholder.success(f"{len(st.session_state.document[file_types[0]]['long'])} ä¸ªæ–‡æ¡£å¤„ç†å®Œæˆï¼", icon="âœ…")

# æ˜¾ç¤ºå†å²å¯¹è¯
display_dialog()
# è‹¥ç”¨æˆ·æé—®
if user_query := st.chat_input("æ‚¨å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨ï¼Ÿ"):
    # æ–‡æ¡£é€‰æ‹©
    try:
        idx = int(st.session_state.document_selected_bot(user_query))
    except:
        idx = 0
    logger.info(f"document selected index: {['æœªæåŠæ—¶é—´', 'æåˆ°ä¸€ä¸ªæ—¶é—´', 'æåˆ°ä¸¤ä¸ªæ—¶é—´', 'æåˆ°å››ä¸ªæ—¶é—´'][idx]}")    
    
    if idx in [0, 1]:   # é€‰æ‹©å•æ–‡æ¡£
        file_id = [st.session_state.rerank(user_query if idx == 1 else user_query + "ï¼Œè¯·æ ¹æ®å¹´åº¦æŠ¥å‘Š", file_names)[0]] if len(file_names) > 1 else 0
    elif idx == 1:   # ä¸¤ä¸ªæ–‡æ¡£
        file_id = st.session_state.rerank(user_query, file_names)[: 2] if len(file_names) > 1 else [0]
    else:   # å››ä¸ªæ–‡æ¡£
        file_id = st.session_state.rerank(user_query + "ç¬¬ä¸€å­£åº¦ã€ç¬¬äºŒå­£åº¦ã€ç¬¬ä¸‰å­£åº¦ã€ç¬¬å››å­£åº¦", file_names)[: 4] if len(file_names) > 1 else [0]
    
    # æ„å›¾è¯†åˆ« 0-é‡‘èé—®ç­”è®¡ç®—, 1-jsonä¿¡æ¯æŠ½å–, 2-ç»Ÿè®¡å›¾è¡¨ç»˜åˆ¶
    intention = st.session_state.rerank(user_query, ["é‡‘èé—®ç­”è®¡ç®—", "jsonä¿¡æ¯æŠ½å–", "ç»Ÿè®¡å›¾è¡¨ç»˜åˆ¶"])[0]
    logger.info(f"query intention: {['é‡‘èé—®ç­”è®¡ç®—', 'jsonä¿¡æ¯æŠ½å–', 'ç»Ÿè®¡å›¾è¡¨ç»˜åˆ¶'][intention]}")
    
    
    # æ˜¾ç¤ºå¹¶å­˜å‚¨æé—®
    st.chat_message("user").markdown(user_query)
    st.session_state.messages.append({"role": "user", "content": user_query})
    if len(file_id) == 1:
        st.info(f"åŒ¹é…å•æ–‡æ¡£ï¼š{file_names[file_id[0]]}", icon="ğŸ“„")
    else:
        st.info(f"åŒ¹é…å¤šæ–‡æ¡£ï¼š{'ã€'.join([file_names[i] for i in file_id])}", icon="ğŸ“„")
    
    if file_types[file_id[0]] == "sheet":   # è¡¨æ ¼é—®ç­”
        response = st.session_state.sheet_chat_bot(user_query, st.session_state.document["sheet"][file_id[0]])
        logger.info(f"chat model response: {response}")
    else:
        # é…ç½®å¤šè·¯å¬å›
        routes = []
        for i in file_id:
            routes += [
                Route(8, st.session_state.embedding, st.session_state.db_long[i], None, None),
                Route(8, None, None, st.session_state.bm25_long[i], None),
                Route(8, st.session_state.embedding, st.session_state.db_short[i], None, None),
                Route(8, None, None, st.session_state.bm25_short[i], None),
                # Route(3, st.session_state.embedding, st.session_state.db_long, None, st.session_state.hyde["concise"]),
                # Route(3, None, None, st.session_state.bm25_long, st.session_state.hyde["glm"]),
                # Route(5, st.session_state.embedding, st.session_state.db_short, None, st.session_state.hyde["step"]),
                # Route(5, None, None, st.session_state.bm25_short, st.session_state.hyde["qwen"])
        ]
        retriever = Retriever(routes, st.session_state.rerank)

        sentences = []
        for i in file_id:
            sentences += [st.session_state.sentences_long[i], st.session_state.sentences_long[i],
                       st.session_state.sentences_short[i], st.session_state.sentences_short[i],
                        # st.session_state.sentences_long, st.session_state.sentences_long,
                        # st.session_state.sentences_short, st.session_state.sentences_short
                        ]

        segment_list = retriever(user_query, 
                                 sentences,
                                 topk=4,
                                 lost_in_the_middle=True)   # é¿å… lost in the middle
        
        logger.info("segment_list: " + "\n\n".join(segment_list))
        
        # è¿”å›æ¨¡å‹å›å¤
        if intention == 0:   # çŸ¥è¯†é—®ç­”
            response = st.session_state.knowledge_chat_bot(user_query, segment_list)
        elif intention == 1:   # ä¿¡æ¯æŠ½å–
            response = st.session_state.knowledge_ie_bot(user_query, segment_list)
            output = re.findall(r'```json(.*?)```', response, re.DOTALL)
            response = output[0] if output else response
            # output = re.findall(r'\{.*?\}', response, re.DOTALL)
            # response = output[0] if output else response
        else:   # å›¾è¡¨
            response = st.session_state.knowledge_chart_bot(user_query, segment_list)
            logger.info(f"chart description: {response}")
            cr = ChartRetriever()
            response = cr(user_query, response)
            if "![img](./tmp/figure.png)" in response:
                st.image("tmp/figure.png", use_column_width=True)
                response = response.replace("![img](./tmp/figure.png)", "")   # streamlitä¸æ”¯æŒmdæ ¼å¼çš„å›¾ç‰‡å±•ç¤º
        
        logger.info(f"{'chat' if intention == 0 else ('ie' if intention == 1 else 'chart')} model response: {response}")
        
        # å¤„ç†è¾“å‡ºæ ¼å¼
        response = add_cite(response, segment_list)

    # å­˜å‚¨è¾“å‡ºå†…å®¹
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    # æ˜¾ç¤ºè¾“å‡º
    with st.chat_message("assistant"):
        st.markdown(response, unsafe_allow_html=True)
